\documentclass[twoside,11pt,a4paper]{article}

% packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx,curves,float,rotating}


\usepackage{amsmath, amssymb, latexsym}  % math stuff
\usepackage{amsfonts}
\usepackage{amsopn}                             % um mathe operatoren zu deklarieren
\usepackage[american]{babel}                     % otherwise use british or american
\usepackage{theorem}                            % instead of \usepackage{amsthm}
\usepackage{dcolumn}
\usepackage{hyperref}
\usepackage[utf8x]{inputenc}
\usepackage{tikz}
\usepackage{algpseudocode}
\usepackage{algorithm}

\newcommand*\Let[2]{\State #1 $\gets$ #2}



% @ environment %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xspace}                             % context sensitive space after macros
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\def\eg{{e.g}\onedot} \def\Eg{{E.g}\onedot}
\def\ie{{i.e}\onedot} \def\Ie{{I.e}\onedot}
\def\cf{{c.f}\onedot} \def\Cf{{C.f}\onedot}
\def\etc{{etc}\onedot} \def\vs{{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{{et al}\onedot}
\def\zB{z.B\onedot} \def\ZB{Z.B\onedot}
\def\dh{d.h\onedot} \def\Dh{D.h\onedot}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%	Macros fuer neue Umgebungen
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand*{\Frac}[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\newlength{\textwd}
\newlength{\oddsidemargintmp}
\newlength{\evensidemargintmp}
\newcommand*{\hspaceof}[2]{\settowidth{\textwd}{#1}\mbox{\hspace{#2\textwd}}}
\newlength{\textht}
\newcommand*{\vspaceof}[3]{\settoheight{\textht}{#1}\mbox{\raisebox{#2\textht}{#3}}}
\newcommand*{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}

\newenvironment{deflist}[1][\quad]%
{  \begin{list}{}{%
      \renewcommand{\makelabel}[1]{\textbf{##1}\hfil}%
      \settowidth{\labelwidth}{\textbf{#1}}%
      \setlength{\leftmargin}{\labelwidth}
      \addtolength{\leftmargin}{\labelsep}}}
{  \end{list}}


\newenvironment{Quote}% Definition of Quote
{  \begin{list}{}{%
      \setlength{\rightmargin}{0pt}}
      \item[]\ignorespaces}
{\unskip\end{list}}


\theoremstyle{break}
\theorembodyfont{\itshape}
\theoremheaderfont{\scshape}

\newtheorem{Cor}{Corollary}
\newtheorem{Def}{Definition}
%\newtheorem{Def}[Cor]{Definition}



\newcolumntype{.}{D{.}{.}{-1}}


\pagestyle{headings}
\textwidth 15cm
\textheight 23cm
\oddsidemargin 1cm
\evensidemargin 0cm
%\parindent 0mm



\begin{document}


\pagestyle{empty}

\begin{center}

    RWTH Aachen University\\
    Chair of Computer Science 6 \\
    Prof. Dr.-Ing. Hermann Ney\\[6ex]
    Selected Topics in Human Language Technology and Pattern Recognition WS 16/17\\[12ex]

    \LARGE
    \textbf{Deep Directed Generative Models} \\[6ex]
    \textit{AndrÃ© Merboldt} \\[6ex]
    \textit{346703} \\[6ex]
    \today

    \vfill
    \Large Supervisor: Tobias Menne
\end{center}

% blank page
\newpage
\
\newpage


% contents
\pagestyle{headings}
\tableofcontents
\listoftables
\listoffigures
%\newpage
%\pagestyle{empty}
%\
\newpage
\pagestyle{headings}


%----------------------------------
% ABSTRACT
%----------------------------------
\input{chapters/abstract}




%----------------------------------
% Motivation
%----------------------------------
\input{chapters/introduction}

%----------------------------------
% Overview of Directed Generative Models
%----------------------------------
\input{chapters/overview}



%----------------------------------
% Sigmoid Belief Networks
%----------------------------------
\input{chapters/sigmoid_belief_nets}

%----------------------------------
% Variational Autoencoders
%----------------------------------
\input{chapters/vae}




%----------------------------------
% Generative Adversarial Netoworks
%----------------------------------
\section{Generative Adversarial Networks}
\label{sec:gan}

Generative Adversarial Networks (GAN) is a framework recently proposed by Goodfellow et al which has gathered a lot of attention in the deep learning community and in the last few years many extensions have been [proposed] (citations).
GANs can be understood as a two-player game where one player is called generator $G$ playing against the discriminator $D$.
The goal of $G$ is to produce similar data to the given training set while $D$ is tasked with discriminating(?) the generated samples from the training data. Both $G$ and $D$ are learning function approximators, for example Multi-Layer Peceptron (MLP) networks as proposed in the original GAN paper.
% --> declare distribution p_data, p_model, x, z
During learning, both networks are updated in parallel according to the gradient of their respective loss function which we will explore now.\\
In the following $p_{data}$ is the true data generating distribution from which the training samples have been generated.
We don't have access to that distribution.

\subsection{Architecture}
\label{sub:gan_arch}


\subsubsection{Generator Network}
The generator network in the GAN framework tries to fool the discriminator $D$ by producing samples which are indistinguishable from the training data.
This process can be formally written as minimizing the following cost function.
$$
\mathcal{C}_g = \log(1 - D(G(z)))
$$
$z$ is produced by sampling from the noise prior $p_g(z)$.\\

Note that this loss function is fully differentiable which means it can be trained with backpropagation.



\subsubsection{Discriminator Network}
The objective of the discriminator network $D$ is to distinguish the generated samples produced by $G$ from the training set samples.
This process can be formalized to maximizing the cost function $\mathcal{C}_d$.
$$
\mathcal{C}_d = \log\big(\log D(x) + \log (1 - D(G(z))\big)
$$



\subsection{Training}
\label{sub:gan_training}
The GAN framework can be fully trained with stochastic backpropagation due to both $D$ and $G$ being differentiable.

Combining the cost functions of generator and discriminator yield us the following objective with value function $V(G,D)$.
$$
\min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
$$
In the original GAN paper an minibatch-based algorithm for training GAN is proposed, but we will take a look at an the online learning version below:\\
\begin{algorithm}
  \caption{Online learning of generative adversarial networks $-$ simple version ($k=1$)}
  \label{alg:gan_online}
  \begin{algorithmic}[1]
    \Let{$\eta_d, \eta_g$}{Learning rate of discriminator and generator networks, respectively}
    \Let{$\theta_d, \theta_g$}{Parameters of function approximators}
    \For{number of training iterations}
      \Let{$z_d$}{sample from noise prior $p_g(z)$}
      \Let{$z_g$}{sample from noise prior $p_g(z)$}
      \Let{$x$}{example from training set}
      \Let{$\theta_d$}{$\theta_d + \eta_d \nabla_{\theta_d} \bigg[\log D(x) + \log \big(1 - D(G(z_d))\big)\bigg]$}
      \Let{$\theta_g$}{$\theta_g - \eta_g \nabla_{\theta_g} \bigg[\log\big(1 - D(G(z_d))\big)\bigg]$}
    \EndFor
  \end{algorithmic}
\end{algorithm}

In algorithm \ref{alg:gan_online} the original algorithm has been modified for single pass (online) learning.
Sampling minibatches from the noise prior and $p_{data}(x)$ result in the minibatch version.
Additionally, it is often required for practical reasons to let the discriminator run multiple backward passes while updating the generator once (why?).
Note that the discriminator will ascend while the generator descend its gradient due to maximizing $\mathcal{C}_d$ but minimizing $\mathcal{C}_g$ (correct?).

\subsection{Stability and Performance}
\label{sub:gan_stability}

\subsubsection{Freeze Learning}
\label{ssub:gan_freeze_learning}

\subsubsection{Feature Matching}
\label{ssub:gan_feature_matching}

\subsubsection{Minibatch discrimination}
\label{ssub:gan_minibatch_discrimination}

\subsubsection{Historical Averaging}
\label{ssub:gan_historical_averaging}


\subsubsection{Label Smoothing}
\label{ssub:gan_label_smoothing}


\subsubsection{Normalizing Flows}
\label{ssub:gan_nf}









\subsection{Application}
\label{sub:gan_application}
GAN have been applied to many different areas which include generating images (GAN, DCGAN, LAPGAN), sequences (SeqGAN), videos (\cite{gan_video:2016}), 3D objects (\cite{gan_3d:2016}), text-to-image synthesis (\cite{gan_t2i:2016})
\subsection{Extensions}
\label{sub:gan_extensions}

\subsubsection{LAPGAN}
\label{ssub:lapgan}

\subsubsection{DCGAN}
\label{ssub:dcgan}





%----------------------------------
% More Generative Directed Models
%----------------------------------
\section{More Generative Directed Models}
\label{sec:more}

\subsection{Generative Moment Matching Networks}
\label{sub:more_mmn}

\subsection{Auto-Regressive Networks}
\label{sub:more_arn}

See \cite{gan_openai:2016} and \cite{gan_training:2016}.


\section{Conclusion}
\label{sec:conclusion}

Generative models have shown great promise to tackle interesting problems.
Academic work is moving incredibly fast and many new ideas and combinations
are being proposed almost daily (citation needed, meta paper?).
For example, VAEs and GANs have been combined (https://github.com/skaae/vaeblog)
which produced way larger images than GANs alone.

% not relevant, but wanted to write about it :p
As mentioned in the motivation, further advances to generative architectures are
likely to solve current issues with depending on large labelled data.
Another large and increasing area of research is semi-supervised learning
(combining learning from labelled data as well as unlabelled data)
and also one-shot learning, which is where humans excel and machines fail currently.
\\\\
Exciting times :)

\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{paper}

\end{document}

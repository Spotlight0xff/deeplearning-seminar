\section{Generative Adversarial Networks}
\label{sec:gan}

%%% when introduced, game theory approach
Generative Adversarial Networks (GAN) is a framework recently proposed by Goodfellow et al based on a game theoretic approach to generative modelling.
%which has gathered a lot of attention in the deep learning community and in the last few years many extensions have been [proposed] (citations).

The idea is to have two neural networks playing against each other.
A generator $G(z)$ and a discriminator $D$ where the generator tries to produce data similar to those encountered in a training set. $D$ receives samples from either the training set or the generated data, without knowing where it came from.
Both $G$ and $D$ are usually implemented as neural networks with $G$ being trained to output samples fooling the discriminator and $D$ distinguishing generated samples from training examples.

% use of words: forgery
To understand the inuition behind the approach to GANs, it may be helpful to view(?) analogy of counterfeiters and the police.
Counterfeiters try to produce fake money imitating legit money while the police tries to distinguish fake from real money.
This procedure of generating and distinguishing will go back-and-forth as the counterfeiters will get better at producing authentic looking money and the police is hard-pressed to differentiate between fake and real.
Eventually, this procedure will result in a nash equlibrium where the police or discriminator will have 50\% chance of seperating authentic from real.

Ideally, we want to find this equilibrium for the GAN model as well.


\newpage


%GANs can be understood as a two-player game where one player is called generator $G$ playing against the discriminator $D$.
%The goal of $G$ is to produce similar data to the given training set while $D$ is tasked with discriminating(?) the generated samples from the training data. Both $G$ and $D$ are learning function approximators, for example Multi-Layer Peceptron (MLP) networks as proposed in the original GAN paper.
% --> declare distribution p_data, p_model, x, z
%During learning, both networks are updated in parallel according to the gradient of their respective loss function which we will explore now.\\
%In the following $p_{data}$ is the true data generating distribution from which the training samples have been generated.
%We don't have access to that distribution.


\begin{figure}[htb]
\centering
\includestandalone[width=\linewidth,mode=buildnew]{media/gan_conceptual}
  \caption{Conceptual figure of generative adversarial network}
  \label{fig:gan_a}
  \medskip
  \small
  The above figure is illustrating the information and gradient flow in the GAN framework.\\
  \emph{data space} denotes the real-world data sampled from $p_{data}$, which we aim to model.
  Dashed arrows denote the gradient flow.
\end{figure}

\newpage

\subsection{Architecture}
\label{sub:gan_arch}
Formalizing the setup in a probabilistic way, we have the unknown data distribution $p_{data}(x)$ from which the training examples have been drawn and the marginalized model distribution $p_{model}(x) = \int p(z)p(x|z) \textit{d}z$ over the noise space $z$ (also latent space).


% http://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-generative-models-and-adversarial-training-upc-2016
% TODO: recreate in tikz


%\begin{figure}[htb]
%\centering
%\includestandalone[mode=buildnew,width=\linewidth]{media/gan_conceptual}
  %\caption{Conceptual idea of generative adversarial networks (source: Summer seminar UPC TelecomBCN)}\label{fig:gan_architecture}
%\end{figure}


\subsubsection{Generator Network}
The generator $G$ in the GAN framework tries to fool the discriminator $D$ by producing samples which are indistinguishable from the training data.
This process can be formally written as minimizing the following cost function.
%Where $z$ is sampling from the noise prior $p(z)$.\\

%Another common form of the generator loss is $\mathcal{L'}_g$.
%$$
$$
\mathcal{L}_g = \min \log(1 - D(G(z)))\\
\mathcal{L'}_g = \max \log D(G(z))
$$
This formulation has the benefit of the same optimum fixed point, but has a better gradient flow early in training when $G$ produces samples which can be distinguished easily from real data by $D$.

Note that this loss function is fully differentiable which means it can be trained with backpropagation.



\subsubsection{Discriminator Network}
The objective of the discriminator network $D$ is to distinguish the generated samples produced by $G$ from the training set samples.
This process can be formalized to maximizing the cost function $\mathcal{L}_d$.
$$
\mathcal{L}_d = \max \log\big(\log D(x) + \log (1 - D(G(z))\big)
$$


\newpage

\subsection{Training}
\label{sub:gan_training}
Combining the loss functions of both generator and discriminator yields us the following objective with value function $V(G,D)$.
$$
\min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
$$

The GAN framework can be fully trained with stochastic backpropagation due to $V(G,D)$ being differentiable.
Training will oscillate between training the generator and discriminator, where the other party is fixed respectively.
In order to avoid a too strong discriminator (or generator), the ratio of learning steps will vary even though there are no hard rules for this.

\vspace{5cm}
\paragraph{Theoretical Foundation}
Using a model with infinite training time and capacity in both generator and discriminator allows theoretical analysis of the GAN framework \cite{gan:2014}.
For any given generator $G$, the optimal discriminator $D$ is given by $D_G^*(x)$:
$$
D_G^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_{model}(x)}
$$

%In the original GAN paper an minibatch-based algorithm for training GAN is proposed, but we will take a look at an the online learning version below:\\
%\begin{algorithm}
  %\caption{Online learning of generative adversarial networks $-$ simple version ($k=1$)}
  %\label{alg:gan_online}
  %\begin{algorithmic}[1]
    %\Let{$\eta_d, \eta_g$}{Learning rate of discriminator and generator networks, respectively}
    %\Let{$\theta_d, \theta_g$}{Parameters of function approximators}
    %\For{number of training iterations}
      %\Let{$z_d$}{sample from noise prior $p_g(z)$}
      %\Let{$z_g$}{sample from noise prior $p_g(z)$}
      %\Let{$x$}{example from training set}
      %\Let{$\theta_d$}{$\theta_d + \eta_d \nabla_{\theta_d} \bigg[\log D(x) + \log \big(1 - D(G(z_d))\big)\bigg]$}
      %\Let{$\theta_g$}{$\theta_g - \eta_g \nabla_{\theta_g} \bigg[\log\big(1 - D(G(z_d))\big)\bigg]$}
    %\EndFor
  %\end{algorithmic}
%\end{algorithm}

%In algorithm \ref{alg:gan_online} the original algorithm has been modified for single pass (online) learning.
%Sampling minibatches from the noise prior and $p_{data}(x)$ result in the minibatch version.
%Additionally, it is often required for practical reasons to let the discriminator run multiple backward passes while updating the generator once (why?).
%Note that the discriminator will ascend while the generator descend its gradient due to maximizing $\mathcal{L}_d$ but minimizing $\mathcal{L}_g$ (correct?).

\newpage

\subsection{Stability and Performance}
\label{sub:gan_stability}
In the practical case where both function approximators $G$ and $D$ are represented using a neural network,
GANs have been shown to be difficult to train using gradient descent.
These issues have been credited to the problem of finding the nash equilibrium in the minimax-game with continious, high-dimensional parameters whereas current gradient-based methods are [designed] to reach an minimum.
Additionally to these hypothetical thoughts, \cite{gan_distinguish_crit:2014} have shown that these methods may fail to converge.
Acknoledging these problems, Salimans et al \cite{improved_gan:2016} has studied the stability and performance of GAN in detail resulting in a number of practical methods improving sample generation and improved semi-supervised learning performance.
We will take a look at a selection of these methods in the following, focussing on neural networks as approximators.

\subsubsection{Freeze Learning}
\label{ssub:gan_freeze_learning}
One of the main issues prominent during early GAN research is the disparity between $G$ and $D$.
Commonly during training one of these networks will outpace the other resulting in degraded gradients where the other player is unable to learn from.
Freeze learning is one of the natural counter to this problem, just freezing either $G$ or $D$ until the other network has catched up (formulation!).
In practice the generator is far slower to train than the discriminator in most cases (citation).


\subsubsection{Label Smoothing}
\label{ssub:gan_label_smoothing}
Another basic idea to improve gradient flow is to replace the binary classification values $0/1$ with smoothed values $0.1/0.9$ or $\epsilon/1-\epsilon$.
This guarantees to provide the generator with an informative gradient to improve learning performance
Additionally, smoothed labels have been shown to reduce the attack surface of neural networks to adversarial examples \cite{adv_examples:2016}.
% TODO replace 0/1 with e/1 âˆ’ e ??
% TODO one-sided label smoothing


\subsubsection{(Virtual) Batch normalization}
\label{ssub:gan_batch_norm}
% TODO explain internal covariate shift?
Batch normalization (BN) \cite{batch_norm:2015} is a recent technique to boost performance in deep neural networks addressing the \emph{internal covariate shift} by normalizing minibatches.
Essentially, BN works by normalizing each sample from a minibatch to the statistics of the whole batch.
In a paper \cite{improved_gan:2016} by Salimans et al on improving stability of the GAN training procedure, a variant of BN has been proposed called virtual batch normalization.


%Using batch normalization \cite{batch_norm:2015} helped stabilizing learning DCGAN \cite{dcgan:2015}.
\cite{improved_gan:2016} introduced virtual batch normalization where each input $x$ is normalized on one reference batch chosen at the start of learning instead of the other inputs in the mini-batch.

\subsubsection{Feature Matching}
\label{ssub:gan_feature_matching}
In computer vision, features are often used to identify relevant pieces of information in images for recognition and classification.
They may refer to a set of points or edges in an image, which exactly is not clearly defined.
With the recent advances in classification tasks performed by deep convolutional networks, automatically learned features have been a large part of that success. (citation!)
Feature matching is an technique designed to improve the learning procedure of GANs where not directly $\mathcal{L}_g$ is maximized but instead also learn the discriminator on intermediate layer activation outputs.
Using this modified procedure the modified objective function aids the generator to output data matching the statistics of the input data.
With $f(x)$ denoting an intermediate layer in $D$, the new objective function becomes:
$$
|| \mathbb{E}_{x \sim p_{data}}f(x) - \mathbb{E}_{z \sim p(z)}f(G(z)) || ^{2}_{2}
$$


\subsubsection{Minibatch discrimination}
\label{ssub:gan_minibatch_discrimination}

\vspace{10cm}

\subsubsection{Historical Averaging}
\label{ssub:gan_historical_averaging}

\newpage




%\subsection{Application}
%\label{sub:gan_application}
%GAN have been applied to many different areas which include generating images (GAN, DCGAN, LAPGAN), sequences (SeqGAN), videos (\cite{gan_video:2016}), 3D objects (\cite{gan_3d:2016}), text-to-image synthesis (\cite{gan_t2i:2016})


\subsection{Extensions}
\label{sub:gan_extensions}

\subsubsection{DCGAN \cite{dcgan:2015}}
\label{ssub:dcgan}
Early implementations of the GAN framework have been implemented using fully-connected layers,
which have proven to be difficult and slow to train on real-world data (citation, original convnet papers?).
Using deep convolutional networks has helped reach human-level performance in object recognition and classification problems on images (citations!).
As the discriminator in the GAN model implements a binary classification task and the generator performance is heavily dependent on the discriminator, using convnets to train the model should improve performance of image generation immensely.
\emph{Deep convolutional generative adversarial network} (DCGAN) has applied convolutional networks to both generator and discriminator, resulting in quantitively evualuated better results.
DCGAN uses no fully connected or pooling layers, but instead fractionally strided convolutions (often wrongfully called deconvolutions).

\subsubsection{LAPGAN \cite{lapgan:2015}}
\label{ssub:lapgan}
LAPGAN is an extension of GAN applied to images using laplacian pyramids \cite{laplacian:1983}.
Instead of using a single generator network, LAPGAN uses a series of deep convolutional networks as generators.

\paragraph{Training} is heavily modified from the regular GAN framework.
In each iteration a training sample is drawn from the dataset and a downsamples version from it is computed.
The discriminator receives now either the computed high-pass image (from the original image and the down-then-up sampled image) or an high-pass image from the generator.
These steps are repeated for other steps, downscaling the image.
In the last stage, a traditional generator and discriminator is used for the $8x8$ image.
\paragraph{Sampling} uses a conditional GAN to produce high-resolution images through different stages of deep generator networks.

\paragraph{Results}
As GANs have no direct measurement of the quality of generations due to their lack of objective function, human evaluation of the authenticity of generated images is used for quantitive results.
LAPGAN has pushed the state of the art significantly, with generated images which are high-resolution in comparison to earlier methods and arguebly high variety of generations.
Furthermore, humans have evaluated the generated images for real images 40\% of the time.



\section{Summary}
\label{sec:summary}

In this article we have taken a look at different directed models which perform generative modeling using deep neural networks.
Variational autoencoders as well as generative adversarial networks have shown to produce good results using large datasets with unsupervised learning.
Deep generative models have shown to learn rich internal representation of high-dimensional data in order to generate samples.
Going further, as intelligent agents will need to have accurate and generalized internal representations inferred through sensory input to reason about the world, generative models are are likely to be the cornerstones of more advanced intelligent systems in the future.

Both models explained in detail have been proposed in recent years with many proposed extensions which were not covered in this article, thus further improvements are likely to happen.

Especially interesting is the case of unsupervised learning, due to vast amount of freely available data on the web and in images, video and audio. Deep learning has been mostly focussed on supervised algorithms, however these methods require most labelled datasets which are often not feasible to obtain.

%Generative models have shown great promise to tackle interesting problems.
%Academic work is moving incredibly fast and many new ideas and combinations
%are being proposed almost daily (citation needed, meta paper?).
%For example, VAEs and GANs have been combined (https://github.com/skaae/vaeblog)
%which produced way larger images than GANs alone.

%% not relevant, but wanted to write about it :p
%As mentioned in the motivation, further advances to generative architectures are
%likely to solve current issues with depending on large labelled data.
%Another large and increasing area of research is semi-supervised learning
%(combining learning from labelled data as well as unlabelled data)
%and also one-shot learning, which is where humans excel and machines fail currently.
%\\\\
%Exciting times :)



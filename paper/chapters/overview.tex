\section{Overview of Directed Generative Models}
\label{sec:overview}


\paragraph{Variational Autoencoders (VAE) \cite{vae:2013}\cite{rezende:2014}}
\label{par:overview_vae}
Variational Autoencoders (VAE) use two networks which are trained jointly using approximated learned inference.
The objective function is aimed at building a reasonable simple latent space and approximating the intractable posterior distribution using variational inference.
It consists of the recognition and inference network which can be understood in the autoencoder jargon as probabilistic encoder and decoder.
Using variational bayesian methods the intractable posterior distribution can be approximated and learned using backpropagation and gradient-based methods.

%But in addition to regular autoencoders encourages the VAE the latent space to match a specific probability distribution.
%This encouragement is done using a variational lower bound on the distribution output by the encoder network.

%where the encoder takes input data and translates it into a latent structure while
%the decoder takes the latent structure and produces data which is as close as possible to the initial input data.

%In the case of VAEs, the distribution is intractable and we can only approximate the posterior distribution.
% intractable -> use neural network, which we can train
% --> no closed form possible
%We use the KL-Divergence to train the network.

% TODO read chapter 19, approximate inference
%In VAEs however, this




\paragraph{Generative Adversarial Networks\cite{gan:2014}}
\label{par:overview_gan}
GANs are a game theoretic approach to generative modelling
in which two networks compete against each other.
The discriminator $D$ is trying to distinguish the generated samples
by the generator $G$ from real world data.
The goal for $G$ however is to produce data as realistic as possible.\\
During the early phase of training, $G$ produces random noise which
is easy to differentiate from groundtruth data.
Both networks are trained in parallel, where both networks try to get better
at their respective objective.
In the best-case scenario is $G$ able to produce data indistinguishly from real world data in which
case the discriminator will only be able to guess correctly with a 50\% chance.
This plateau is called Nash equilibrium (citation needed).




